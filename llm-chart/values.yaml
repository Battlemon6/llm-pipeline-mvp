seedApp:
  replicaCount: 1
  image:
    repository: europe-west2-docker.pkg.dev/llm-pipeline-birkbeck/llm-app-images/seed-app
    tag: "v3"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 8000
    metricsPort: 8000
  env:
    VLLM_ENDPOINT: "http://vllm-server:8000"
    VLLM_MODEL: "TheBloke/Mistral-7B-Instruct-v0.2-AWQ"
    VLLM_TIMEOUT: "120"

vllm:
  replicaCount: 1
  image:
    repository: vllm/vllm-openai
    tag: "latest"
    pullPolicy: IfNotPresent

  model: "TheBloke/Mistral-7B-Instruct-v0.2-AWQ"
  quantization: "awq"
  gpuMemoryUtilization: 0.8

  persistence:
    enabled: true
    size: 20Gi
    storageClassName: "premium-rwo"

  service:
    port: 8000
    metricsPort: 8000

  nodeSelector:
    cloud.google.com/gke-accelerator: "nvidia-l4"

  tolerations:
    - key: "nvidia.com/gpu"
      operator: "Exists"
      effect: "NoSchedule"

  resources:
    requests:
      nvidia.com/gpu: 1
    limits:
      nvidia.com/gpu: 1

# --- DÜZELTİLMİŞ BÖLÜM ---

# kube-prometheus-stack alt chart'ını etkinleştir ve ayarlarını aşağıya ilet
prometheus:
  # Ayarları alt chart'a (kube-prometheus-stack) gönderir
  prometheus:
    prometheusSpec:
      nodeSelector:
        cloud.google.com/gke-accelerator: null
  alertmanager:
    alertmanagerSpec:
      nodeSelector:
        cloud.google.com/gke-accelerator: null
  grafana:
    nodeSelector:
      cloud.google.com/gke-accelerator: null
  prometheusOperator:
    serviceMonitorSelectorNilUsesHelmValues: false

# dcgm-exporter alt chart'ını etkinleştir ve ayarlarını aşağıya ilet
dcgmExporter:
  # Ayarları alt chart'a (dcgm-exporter) gönderir
  tolerations:
    - key: "nvidia.com/gpu"
      operator: "Exists"
      effect: "NoSchedule"
  serviceMonitor:
    enabled: true